import cv2
import numpy as np
import streamlit as st
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
import time
import csv
from playsound import playsound

# Charger le mod√®le
model = load_model(r'C:\Users\frede\Desktop\TPE_2024\action.h5')  # Chemin vers votre mod√®le .h5

# Dictionnaire d'actions avec des ic√¥nes pour chaque geste
actions = {
    'hello': 'üñêÔ∏è',
    'thanks': 'üôè',
    'iloveyou': 'ü§ü',
    'call': 'ü§≤',
    'yes': 'üëç',
    
}

# Dimensions pour redimensionner l'image
width, height = 1662, 1662

# Configurer l'interface Streamlit
st.set_page_config(page_title="Reconnaissance Avanc√©e de Langue des Signes", page_icon="üñêÔ∏è")

# En-t√™te avec logos et titre centralis√©
st.markdown(
    """
    <style>
    .title { font-size: 1.8rem; font-weight: bold; color: #4a4a4a; text-align: center; }
    .flash { animation: flash 0.5s ease-in-out; color: #FF6347; font-weight: bold; }
    .pred-box { background-color: #f8f9fa; padding: 10px; border-radius: 5px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); }
    .captured-image { width: 100%; max-width: 500px; margin-top: 20px; }
    </style>
    """, unsafe_allow_html=True
)

# Colonnes pour le logo et le titre
col1, col2, col3 = st.columns([1, 2, 1])
with col1:
    st.image("C:/Users/frede/Desktop/TPE_2024/Projet Tpe/logo_vnu.jpg", width=100)
with col2:
    st.markdown("<div class='title'>Reconnaissance Avanc√©e de Langue des Signes</div>", unsafe_allow_html=True)
with col3:
    st.image("C:/Users/frede/Desktop/TPE_2024/Projet Tpe/logo_ifi.jpg", width=100)

# Introduction de l'application
st.markdown(
    "<p style='text-align: center; color: #6c757d; font-size: 1.1rem;'>"
    "Cette application utilise l'apprentissage profond pour reconna√Ætre et interpr√©ter des signes en temps r√©el."
    "</p>", unsafe_allow_html=True
)

# Sidebar avec Guide d'Utilisation d√©roulant
st.sidebar.title("Guide d'Utilisation")
with st.sidebar.expander("Cliquez ici pour le guide d'utilisation"):
    st.write("""
    1. **D√©marrer la Webcam** : Activez la webcam pour lancer la d√©tection en temps r√©el des gestes.
    2. **Voir la Pr√©diction** : Observez la pr√©diction de geste affich√©e sur l'image en direct.
    3. **Arr√™ter la Webcam** : Arr√™tez la d√©tection en temps r√©el √† tout moment en cliquant sur ce bouton.
    4. **Options Avanc√©es** :
        - **Activer le son** : Joue un son lorsque le geste est d√©tect√©.
        - **Capture automatique d'image** : Capture automatiquement une image pour chaque geste d√©tect√©.
        - **Sauvegarder l'historique des pr√©dictions** : Sauvegarde chaque pr√©diction dans un fichier CSV pour un historique.
    """)

st.sidebar.header("R√©sultat de la Pr√©diction")
prediction_placeholder = st.sidebar.empty()

# Options avanc√©es
st.sidebar.markdown("### Options avanc√©es")
play_sound = st.sidebar.checkbox("Activer le son pour chaque nouveau geste")
auto_capture = st.sidebar.checkbox("Activer la capture automatique d'image")
save_to_csv = st.sidebar.checkbox("Sauvegarder l'historique des pr√©dictions")

# Historique des pr√©dictions
st.sidebar.header("Historique des gestes d√©tect√©s")
history_placeholder = st.sidebar.empty()
predictions_history = []

# D√©marrer la webcam
placeholder = st.empty()

# Boutons de d√©marrage, d'arr√™t et de capture d'images
col1, col2, col3 = st.columns(3)
with col1:
    start_webcam = st.button("D√©marrer la Webcam")
with col2:
    stop_webcam = st.button("Arr√™ter la Webcam")
with col3:
    capture_image = st.button("Capturer Image")

if start_webcam:
    cap = cv2.VideoCapture(0)
    stframe = placeholder.empty()
    previous_prediction = None
    captured_image = None
    save_path = "gesture_predictions.csv"

    # Initialiser le fichier CSV pour sauvegarder les pr√©dictions
    if save_to_csv:
        with open(save_path, mode='w', newline='') as file:
            writer = csv.writer(file)
            writer.writerow(["Timestamp", "Geste d√©tect√©"])

    while start_webcam and cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            st.write("Erreur: Impossible de lire la vid√©o.")
            break

        frame_resized = cv2.resize(frame, (width, height))
        gray_frame = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY) / 255.0
        gray_frame = np.expand_dims(img_to_array(gray_frame), axis=0)

        # Pr√©diction
        prediction = model.predict(gray_frame)
        predicted_action = actions[np.argmax(prediction)]

        # Notification sonore et flash si la pr√©diction change
        if predicted_action != previous_prediction:
            if play_sound:
                playsound('sound_notification.mp3')
            prediction_placeholder.markdown(
                f"<div class='flash'><b>Geste d√©tect√© :</b> {predicted_action}</div>",
                unsafe_allow_html=True
            )
            previous_prediction = predicted_action

            # Sauvegarder dans l'historique
            timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
            predictions_history.append(f"{timestamp} - {predicted_action}")
            history_placeholder.write("\n".join(predictions_history))

            # Enregistrer l'historique dans un fichier CSV
            if save_to_csv:
                with open(save_path, mode='a', newline='') as file:
                    writer = csv.writer(file)
                    writer.writerow([timestamp, predicted_action])

        else:
            prediction_placeholder.markdown(
                f"<div class='pred-box'><b>Geste d√©tect√© :</b> {predicted_action}</div>",
                unsafe_allow_html=True
            )

        # Afficher le flux vid√©o avec la pr√©diction
        cv2.putText(frame, f'{predicted_action}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        # Capture automatique d'image
        if auto_capture:
            img_name = f"gesture_{predicted_action}_{timestamp}.png"
            cv2.imwrite(img_name, frame)
            captured_image = img_name
            st.sidebar.write(f"Image captur√©e automatiquement sous {img_name}")

        # Afficher le flux vid√©o
        stframe.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), channels="RGB", use_column_width=True)

        # Arr√™ter la webcam
        if stop_webcam:
            break

    cap.release()
    cv2.destroyAllWindows()
    placeholder.empty()
    st.sidebar.write("La webcam est arr√™t√©e.")
else:
    placeholder.write("Cliquez sur **D√©marrer la Webcam** pour lancer la reconnaissance des gestes.")

# Pied de page avec bibliographie et photo
st.markdown("---")
col1, col2 = st.columns([1, 4])

with col1:
    st.image("C:/Users/frede/Desktop/TPE_2024/Projet Tpe/photo.jfif", width=100)

with col2:
    st.markdown(
        """
        <div style='text-align: left; font-size: 0.9rem; color: #6c757d;'>
        Application d√©velopp√©e par Ing.Takouchouang Fraisse Sacre, √âtudiant √† l'IFI - Promotion 27.<br><br>
        <b>Bibliographie :</b><br>
        - [1] Takouchouang Fraisse Sacre.<br>
        - [2] Camerounaise.<br>
        - [3] Etudiant en Master I a l'IFI(Institut Francophone International) , en Informatique option Systeme Intelligent et Multimedia(SIM), en double Diplomation , de la Promotion 27.
        </div>
        """, unsafe_allow_html=True
    )
